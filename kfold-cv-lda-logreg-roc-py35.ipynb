{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA & Logit K-Fold Cross Validation\n",
    "### Compatible with Python 2.7, 3.5, 3.6\n",
    "#### Plot ROC Curve with Optimal Cutoffs and Accuracy Rates\n",
    "John Bonfardeci\n",
    "2017-04-09\n",
    "Modified: 2017-04-16\n",
    "\n",
    "#### What this notebook does:\n",
    "* Create randomized K cross-validation (CV) groups\n",
    "* For-each CV:\n",
    "    * Split randomized data into (k-1)/k training data and 1/k testing\n",
    "    * Run LDA K times\n",
    "        * Find best cutoff with test cutoff set\n",
    "        * Output Confusion Matrix, misclassification, and accuracy rates\n",
    "        * Plot ROC combined with K curves (does not plot cutoff points - these are printed out though)\n",
    "        * Optional - output images and data to Excel\n",
    "    \n",
    "    * Run Logistic Regression K times\n",
    "        * Find best cutoff with test cutoff set\n",
    "        * Output Confusion Matrix, misclassification, and accuracy rates\n",
    "        * Plot ROC combined with K curves (does not plot cutoff points - these are printed out though)\n",
    "        * Optional - output images and data to Excel\n",
    "    \n",
    "Directions in Jupyter Notebook: Select `Cell -> Run All`. \n",
    "Look for printed output and ROC plots at bottom of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change These Parameters\n",
    "\n",
    "# relative file path; can place in same working directory as notebook\n",
    "file_path = 'hof_data.csv'\n",
    "\n",
    "# the column names of the continuous predictors\n",
    "feature_names = ['H','HR','RBI','AVG','SLG','OBP']\n",
    "\n",
    "# the column names of the categorical predictors\n",
    "categorical_features = ['POS'] # DOES NOT HANDLE CATEGORICAL PREDICTORS AT THIS TIME\n",
    "# ...here's why: \n",
    "# http://stats.stackexchange.com/questions/158772/can-we-use-categorical-independent-variable-in-discriminant-analysis#158781)\n",
    "\n",
    "# name of target column\n",
    "target_name = 'HOF'\n",
    "\n",
    "# what value represents the positive value in a binary response: e.g. 1, 'Y', 'T', ...\n",
    "target_value = 'Y' \n",
    "\n",
    "# test thresholds to try\n",
    "test_cutoffs = [0.10, 0.25, 0.50, 0.75, 0.90] \n",
    "\n",
    "# LDA Solver to use. \n",
    "#    Options: \n",
    "#        'lsqr' (Least squares solution) - can use with shrikage\n",
    "#        'svd' (Singular value decomposition) - use with large num features\n",
    "#        'eigen' (Eigenvalue decomposition) - can use with shrikage\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
    "lda_solver = 'lsqr'\n",
    "\n",
    "# change to None to run LDA without shrinkage\n",
    "# Options: None, 'auto', float between 0 and 1\n",
    "# see http://scikit-learn.org/stable/auto_examples/classification/plot_lda.html#sphx-glr-auto-examples-classification-plot-lda-py\n",
    "lda_shrinkgage = 'auto'\n",
    "\n",
    "# number of cross-validation groups to run\n",
    "num_cv = 5\n",
    "\n",
    "# Use Dimensionality reduction with Principal Component Analysis\n",
    "use_pca = True\n",
    "pca_n_components = 2 # number of eigenvalues to keep; should explain 90% or more of the variance\n",
    "\n",
    "# Turn on feature (variable) selection and remove features with low variance.\n",
    "# More at http://scikit-learn.org/stable/modules/feature_selection.html\n",
    "#feature_selection = True\n",
    "\n",
    "# Feature selection removes all features whose variance doesnâ€™t meet this threshold.\n",
    "#feature_selection_threshold = 0.8\n",
    "\n",
    "output_data_to_excel = True\n",
    "output_dir = 'lda-logit\\\\'\n",
    "save_figs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the links below proved helpful in the researh for writing this notebook.\n",
    "* http://sebastianraschka.com/Articles/2014_python_lda.html#introduction\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
    "* https://en.wikipedia.org/wiki/Sensitivity_and_specificity\n",
    "* https://en.wikipedia.org/wiki/Youden%27s_J_statistic\n",
    "* http://stats.stackexchange.com/questions/29719/how-to-determine-best-cutoff-point-and-its-confidence-interval-using-roc-curve-i\n",
    "* https://sasshowcase.wordpress.com/category/sas-macro/\n",
    "* http://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "* https://www.medcalc.org/manual/roc-curves.php\n",
    "* http://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/NCSS/One_ROC_Curve_and_Cutoff_Analysis.pdf\n",
    "* http://www.umich.edu/~ners580/ners-bioe_481/lectures/pdfs/1978-10-semNucMed_Metz-basicROC.pdf\n",
    "* http://scikit-learn.org/stable/modules/cross_validation.html\n",
    "* http://stats.stackexchange.com/questions/95797/how-to-split-the-dataset-for-cross-validation-learning-curve-and-final-evaluat\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "* http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "* http://gim.unmc.edu/dxtests/roc2.htm\n",
    "* https://codeyarns.com/2014/10/27/how-to-change-size-of-matplotlib-plot/\n",
    "* https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "* http://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix\n",
    "* http://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DON'T change below this line unless you know what your're doing.\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from copy import copy\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "#from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0]\n",
      "[[3771  755 2297  305  555  374]\n",
      " [1022   57  366  254  347  292]\n",
      " [1832  336 1122  277  485  337]\n",
      " [ 999  130  433  255  412  320]\n",
      " [ 260   37  109  236  393  304]]\n"
     ]
    }
   ],
   "source": [
    "# load the data into Pandas Dataframe object\n",
    "usecols = copy(feature_names).append(target_name)\n",
    "\n",
    "df = pd.read_csv(file_path, usecols=usecols) # returns new Pandas DataFrame \n",
    "\n",
    "# randomize rows (http://quabr.com/29576430/shuffle-dataframe-rows)\n",
    "#df = _df.iloc[np.random.permutation(len(df))]\n",
    "\n",
    "# create new series with target value converted to 1/0 for the binary responses\n",
    "y = pd.Series( map(lambda x: 1 if x == target_value else 0, df[target_name]) ).as_matrix() # <class 'pandas.core.series.Series'>\n",
    "\n",
    "# get our predictor variables as a multidimensional array (matrix)\n",
    "X = df[feature_names].as_matrix() # <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "cat = df[categorical_features].as_matrix() # <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "# check the X and y data\n",
    "print(y[0:5])\n",
    "print(X[0:5])\n",
    "\n",
    "# good to go..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_balanced_accuracy(tpr, fpr):\n",
    "    \"\"\"\n",
    "    Balanced Accuracy\n",
    "    Dr. Alan Dabney\n",
    "    \n",
    "    @param tpr: float (True Positive Rate - the Sensitivity)\n",
    "    @param fpr: float (False Positive Rate - the 1-Specificity)\n",
    "    @returns float\n",
    "    \"\"\"\n",
    "    return (tpr / (1-fpr)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "def get_confusion_matrix(cutoff, actual, prob):\n",
    "    \"\"\"\n",
    "    Putting a threshold/cutoff on the output of a regression problem, \n",
    "    to determine whether the value is greater or lower than a fixed threshold, \n",
    "    is a binary classification problem.\n",
    "    \n",
    "    TN | FP\n",
    "    -------\n",
    "    FN | TP\n",
    "    \n",
    "    For example: \n",
    "    \n",
    "       n=165   | Predicted NO | Predicted YES\n",
    "    ------------------------------------------\n",
    "    Actual NO  |       50     |      10       |\n",
    "    ------------------------------------------\n",
    "    Actual YES |       5      |      100      |\n",
    "    ------------------------------------------\n",
    "    \n",
    "    The diagonal elements represent the number of points for which the predicted label is equal to the true label,\n",
    "    while off-diagonal elements are those that are mislabeled by the classifier.\n",
    "    The higher the diagonal values of the confusion matrix the better, indicating many correct predictions.\n",
    "    \"\"\"\n",
    "    pred = []\n",
    "    for (x, y) in prob:\n",
    "        pred.append(1 if y > cutoff else 0)\n",
    "\n",
    "    return confusion_matrix(actual, pred)\n",
    "\n",
    "\n",
    "def get_tpr_fpr(cm):\n",
    "    \"\"\"\n",
    "    Sensitivity: TruePos / (True Pos + False Neg) \n",
    "    Specificity: True Neg / (False Pos + True Neg)\n",
    "    TN | FP\n",
    "    -------\n",
    "    FN | TP\n",
    "    \"\"\"\n",
    "    \n",
    "    tn = float(cm[0][0])\n",
    "    fp = float(cm[0][1])\n",
    "    fn = float(cm[1][0])\n",
    "    tp = float(cm[1][1])\n",
    "    \n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = 1-(tn / (fp + tn))\n",
    "    \n",
    "    return [tpr, fpr]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(C):\n",
    "    \"\"\"\n",
    "    Get the accuracy rate of a confusion matrix\n",
    "    TN | FP\n",
    "    -------\n",
    "    FN | TP\n",
    "    \"\"\"\n",
    "    assert C.shape == (2,2), \"Confusion matrix should be from binary classification only.\"\n",
    "    # true negative, false positive, etc...\n",
    "    tn = C[0,0]; fp = C[0,1]; fn = C[1,0]; tp = C[1,1];\n",
    "\n",
    "    NP = fn+tp # Num positive examples\n",
    "    NN = tn+fp # Num negative examples\n",
    "    N  = NP+NN\n",
    "    accuracy = (tp+tn+0.)/N\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def show_confusion_matrix(C, class_labels=['0','1'], figsize=(6,6), fontsize=12, filename='roc-curve'):\n",
    "    \"\"\"\n",
    "    C: ndarray, shape (2,2) as given by scikit-learn confusion_matrix function\n",
    "    class_labels: list of strings, default simply labels 0 and 1.\n",
    "\n",
    "    Draws confusion matrix with associated metrics.\n",
    "    https://notmatthancock.github.io/2015/10/28/confusion-matrix.html\n",
    "    \"\"\"\n",
    "    assert C.shape == (2,2), \"Confusion matrix should be from binary classification only.\"\n",
    "    \n",
    "    # true negative, false positive, etc...\n",
    "    tn = C[0,0]; fp = C[0,1]; fn = C[1,0]; tp = C[1,1];\n",
    "\n",
    "    NP = fn+tp # Num positive examples\n",
    "    NN = tn+fp # Num negative examples\n",
    "    N  = NP+NN\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax  = fig.add_subplot(111)\n",
    "    ax.imshow(C, interpolation='nearest', cmap=plt.cm.gray)\n",
    "\n",
    "    # Draw the grid boxes\n",
    "    ax.set_xlim(-0.5,2.5)\n",
    "    ax.set_ylim(2.5,-0.5)\n",
    "    ax.plot([-0.5,2.5],[0.5,0.5], '-k', lw=2)\n",
    "    ax.plot([-0.5,2.5],[1.5,1.5], '-k', lw=2)\n",
    "    ax.plot([0.5,0.5],[-0.5,2.5], '-k', lw=2)\n",
    "    ax.plot([1.5,1.5],[-0.5,2.5], '-k', lw=2)\n",
    "\n",
    "    # Set xlabels\n",
    "    ax.set_xlabel('Predicted', fontsize=fontsize)\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels(class_labels + [''])\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.xaxis.tick_top()\n",
    "    # These coordinate might require some tinkering. Ditto for y, below.\n",
    "    ax.xaxis.set_label_coords(0.34,1.06)\n",
    "\n",
    "    # Set ylabels\n",
    "    ax.set_ylabel('Actual', fontsize=fontsize, rotation=90)\n",
    "    ax.set_yticklabels(class_labels + [''],rotation=90)\n",
    "    ax.set_yticks([0,1,2])\n",
    "    ax.yaxis.set_label_coords(-0.09,0.65)\n",
    "\n",
    "\n",
    "    # Fill in initial metrics: tp, tn, etc...\n",
    "    ax.text(0,0,\n",
    "            'True Neg: %d\\n(Num Neg: %d)'%(tn,NN),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,1,\n",
    "            'False Neg: %d'%fn,\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,0,\n",
    "            'False Pos: %d'%fp,\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "\n",
    "    ax.text(1,1,\n",
    "            'True Pos: %d\\n(Num Pos: %d)'%(tp,NP),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    # Fill in secondary metrics: accuracy, true pos rate, etc...\n",
    "    ax.text(2,0,\n",
    "            'False Pos Rate: %.2f'%(fp / (fp+tn+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(2,1,\n",
    "            'True Pos Rate: %.2f'%(tp / (tp+fn+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(2,2,\n",
    "            'Accuracy: %.2f'%((tp+tn+0.)/N),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,2,\n",
    "            'Neg Pre Val: %.2f'%(1-fn/(fn+tn+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,2,\n",
    "            'Pos Pred Val: %.2f'%(tp/(tp+fp+0.)),\n",
    "            va='center',\n",
    "            ha='center',\n",
    "            bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "\n",
    "    if save_figs:\n",
    "        if(use_pca):\n",
    "            filename = filename+'-pca'\n",
    "        \n",
    "        filename = '%s%s.png' % (output_dir, filename)\n",
    "        plt.savefig(filename)\n",
    "        print('Confusion matrix image was saved to: %s' % (filename))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_roc(kfolds, mean_tpr, mean_fpr, title, lw=2, filename='roc'):\n",
    "    \"\"\"\n",
    "    Display and save ROC curve\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,12))\n",
    "    colors = cycle(['cyan', 'red', 'seagreen', 'darkorange', 'blue'])\n",
    "    \n",
    "    # Plot the ROC Curve for this CV group\n",
    "    i=0\n",
    "    for (k, color) in zip(kfolds, colors):\n",
    "        tpr, fpr = k[0], k[1]\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=lw, color=color, label='ROC fold %d (area = %0.2f)' % (i+1, roc_auc))\n",
    "        i += 1\n",
    "    \n",
    "    # Plot the ROC Curve for logistic regression\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=lw, color='k', label='Luck')\n",
    "\n",
    "    mean_tpr /= len(kfolds)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    \n",
    "    plt.plot(mean_fpr, mean_tpr, color='g', linestyle='--', label='Mean ROC (area = %0.2f)' % mean_auc, lw=lw)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive (1-Specificity)')\n",
    "    plt.ylabel('True Positive (Sensitivity)')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    if save_figs:\n",
    "        if(use_pca):\n",
    "            filename = filename+'-pca'\n",
    "        \n",
    "        filename = '%s%s.png' % (output_dir, filename)\n",
    "        plt.savefig(filename)\n",
    "        print('ROC image was saved to: %s' % (filename))\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Output to Excel\n",
    "def output_excel(filename, prob, x, y, predicted, sheetname='Sheet1'):\n",
    "    \"\"\"\n",
    "    Output data k-fold data to Excel\n",
    "    \"\"\"\n",
    "    prob_cols = [target_name, 'Prob[0]', 'Prob[1]', 'Predicted']\n",
    "    col_names = []\n",
    "    \n",
    "    if(use_pca and len(feature_names) > len(x[0])):\n",
    "        for i in range(len(x[0])):\n",
    "            col_names.append('Prin%d'%(i))\n",
    "            \n",
    "    else:\n",
    "        col_names = np.asarray(feature_names)    \n",
    "    \n",
    "    col_names = np.append( np.asarray(col_names), np.asarray(prob_cols))\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    i = 0\n",
    "    for xrow, yrow, prob, pred in zip(x, y, prob, predicted):\n",
    "        a = []\n",
    "        for col in xrow:\n",
    "            a.append(col)\n",
    "\n",
    "        a.append(yrow)\n",
    "        a.append(prob[0])\n",
    "        a.append(prob[1])\n",
    "        a.append(pred)\n",
    "        data.append(a)\n",
    "        i+=1\n",
    "\n",
    "    df = pd.DataFrame(data=data, columns=col_names)\n",
    "    if(use_pca):\n",
    "        filename = filename+'-pca'\n",
    "        \n",
    "    filename = '%s%s.xlsx'%(output_dir, filename)\n",
    "    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "    df.to_excel(writer, sheet_name=sheetname)\n",
    "    writer.save()\n",
    "    \n",
    "    print('Excel file was saved to: %s' % (filename))\n",
    "    \n",
    "\n",
    "def output_roc(filename, sheetname, tpr, fpr, cutoffs):\n",
    "    \"\"\"\n",
    "    Output ROC data to Excel\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for (t, f, c) in zip(tpr, fpr, cutoffs):\n",
    "        data.append([t, f, c])\n",
    "        \n",
    "    df = pd.DataFrame(data=data, columns=['Sensitivity', '1-Specificity', 'Cutoff'])\n",
    "    if(use_pca):\n",
    "        filename = filename+'-pca'\n",
    "       \n",
    "    filename = '%s%s.xlsx'%(output_dir, filename) \n",
    "    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "    df.to_excel(writer, sheet_name=sheetname)\n",
    "    writer.save()\n",
    "    print('ROC image was saved to %s'%(filename))\n",
    "\n",
    "            \n",
    "def output_cms(filename, data, sheetname='Sheet1'):\n",
    "    \"\"\"\n",
    "    Output Cutofs, TPR, FPR, Confusion, ... to Excel \n",
    "    \"\"\"\n",
    "    \n",
    "    cols = ['Method', 'FoldNum', 'Cutoff', 'Sensitivity', '1-Specificity', \n",
    "            'TrueNeg', 'FalsPos', 'FalseNeg', 'TruePos', 'Accuracy', 'AUC', 'Balanced Accuracy']\n",
    "\n",
    "    df = pd.DataFrame(data=data, columns=cols)\n",
    "    df.sort(['FoldNum', 'Cutoff'])\n",
    "    if(use_pca):\n",
    "        filename = filename+'-pca'\n",
    "        \n",
    "    filename = '%s%s.xlsx'%(output_dir, filename)\n",
    "    writer = pd.ExcelWriter(filename, engine='xlsxwriter')\n",
    "    df.to_excel(writer, sheet_name=sheetname)\n",
    "\n",
    "    writer.save()\n",
    "    print('Excel file was saved to: %s' % (filename))\n",
    "    \n",
    "    \n",
    "def get_cm_row(method, foldnum, cutoff, actual, prob):\n",
    "    \"\"\"\n",
    "    Create new row for output: Cutofs, TPR, FPR, Confusion, ... to Excel \n",
    "\n",
    "    TN | FP\n",
    "    -------\n",
    "    FN | TP\n",
    "    \"\"\"\n",
    "    cm = get_confusion_matrix(cutoff, actual, prob)\n",
    "    tn = cm[0][0]; fp = cm[0][1]; fn = cm[1][0]; tp = cm[1][1]\n",
    "    tpr, fpr = get_tpr_fpr(cm)\n",
    "    accuracy = get_accuracy(cm)\n",
    "    _fpr, _tpr, cutoffs = roc_curve(actual, prob[:, 1])\n",
    "    _auc = auc(_fpr, _tpr)\n",
    "    ba = get_balanced_accuracy(tpr, fpr)\n",
    "    \n",
    "    return(method, foldnum, cutoff, tpr, fpr, tn, fp, fn, tp, accuracy, _auc, ba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95461248  0.04136611]\n"
     ]
    }
   ],
   "source": [
    "# Dimension Reduction with PCA\n",
    "def get_pca(X, n_components, svd_solver='full'):\n",
    "    pca = PCA(n_components=(n_components if len(X[0]) > 1 else 1), svd_solver=svd_solver)\n",
    "    pca.fit(X)\n",
    "    eigenvalues = pca.explained_variance_ratio_\n",
    "    print(eigenvalues)\n",
    "    return pca.transform(X)\n",
    "\n",
    "\n",
    "if use_pca:\n",
    "    X = get_pca(X, pca_n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'xlsxwriter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-2f8cfec8f4f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moutput_data_to_excel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0moutput_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lda-fold-%d-test'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_actual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TestSet%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         output_excel('lda-fold-%d-train' % (i+1), \n\u001b[0;32m     46\u001b[0m                      lda.predict_proba(train_X), train_X, train_y, train_predicted, 'TrainSet%d' % (i+1))\n",
      "\u001b[1;32m<ipython-input-28-b022dd8e1341>\u001b[0m in \u001b[0;36moutput_excel\u001b[1;34m(filename, prob, x, y, predicted, sheetname)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%s%s.xlsx'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'xlsxwriter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msheetname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\bonfardeci-j\\Anaconda2\\envs\\python35\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, **engine_kwargs)\u001b[0m\n\u001b[0;32m   1424\u001b[0m                  date_format=None, datetime_format=None, **engine_kwargs):\n\u001b[0;32m   1425\u001b[0m         \u001b[1;31m# Use the xlsxwriter module as the Excel writer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mxlsxwriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m         super(_XlsxWriter, self).__init__(path, engine=engine,\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'xlsxwriter'"
     ]
    }
   ],
   "source": [
    "# Run LDA with cross-validation and plot ROC curves\n",
    "rand = np.random.RandomState(0)\n",
    "cv = StratifiedKFold(n_splits=num_cv, shuffle=True, random_state=rand)\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100) # `linspace` returns evenly spaced numbers over a specified interval.\n",
    "roc_kfolds = []\n",
    "cm_folds = []\n",
    "lda_actual = []\n",
    "lda_prob = []\n",
    "\n",
    "# For each cross-validation batch, fit model 80:20 split, plot ROC, and get cutoff\n",
    "# TODO - add feature selection per CV\n",
    "# train, test are of type <type 'numpy.ndarray'>\n",
    "i = 0\n",
    "for (train, test) in cv.split(X, y):\n",
    "\n",
    "    test_actual = y[test]\n",
    "    test_X = X[test]\n",
    "    train_X = X[train]\n",
    "    train_y = y[train]\n",
    "    \n",
    "    # train LDA on training dataset\n",
    "    lda = LinearDiscriminantAnalysis(solver=lda_solver,  \n",
    "                                     shrinkage=lda_shrinkgage).fit(train_X, train_y)\n",
    "       \n",
    "    # test LDA on test dataset\n",
    "    # predict probability returns <type 'numpy.ndarray'> (n_samples, n_classes)\n",
    "    prob = lda.predict_proba(test_X)\n",
    "    \n",
    "    # get predicted values: 1/0; default threshold/cutoff is 0.5\n",
    "    predicted = lda.predict(test_X)\n",
    "    train_predicted = lda.predict(train_X)\n",
    "    \n",
    "    # Compute ROC curve\n",
    "    # fpr = false positive rate (1-specificity)\n",
    "    # tpr = true positive rate (sensitivity)\n",
    "    fpr, tpr, thresholds = roc_curve(test_actual, prob[:, 1]) # returns <type 'numpy.ndarray'> x 3\n",
    "    \n",
    "    # add mean Sensitivity\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "  \n",
    "    if output_data_to_excel:\n",
    "        output_excel('lda-fold-%d-test' % (i+1), prob, test_X, test_actual, predicted, 'TestSet%d' % (i+1))\n",
    "        output_excel('lda-fold-%d-train' % (i+1), \n",
    "                     lda.predict_proba(train_X), train_X, train_y, train_predicted, 'TrainSet%d' % (i+1))\n",
    "    # /if...\n",
    "    \n",
    "    # get_cm_row(method, foldnum, cutoff, actual, prob)\n",
    "    # append confusion matrix rows for output to Excel\n",
    "    for cutoff in test_cutoffs:\n",
    "        cm_folds.append( get_cm_row('LDA', i+1, cutoff, test_actual, prob) )\n",
    "    \n",
    "    \n",
    "    lda_actual.extend(test_actual)\n",
    "    lda_prob.extend(prob)\n",
    "    \n",
    "    roc_kfolds.append([tpr, fpr])\n",
    "    \n",
    "    #output_cutoffs(i, tpr, fpr, thresholds, prob)\n",
    "    \n",
    "    i += 1\n",
    "#/for (train, test)...\n",
    "\n",
    "show_roc(roc_kfolds, mean_tpr, mean_fpr, 'ROC Curves for LDA with K-fold Cross-validation', 2, 'lda-roc')\n",
    "\n",
    "if output_data_to_excel:\n",
    "    output_cms('lda-cms', cm_folds, 'LDA_Test_Folds') # output to excel\n",
    " \n",
    "\n",
    "#Determine the best cutoff points and output confusion matrix\n",
    "#best_tp = get_confusion_matrix(0.1, logit_actual, logit_prob)\n",
    "#best_accuracy =  get_confusion_matrix(0.5, logit_actual, logit_prob)\n",
    "#show_confusion_matrix(best_tp, ['0','1'], (6,6), 12, 'lda-best-tp-cm')\n",
    "#show_confusion_matrix(best_accuracy, ['0','1'], (6,6), 12, 'lda-best-accuracy-cm')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run logistic Regression with cross-validation and plot ROC curves\n",
    "\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100) # `linspace` returns evenly spaced numbers over a specified interval.\n",
    "roc_kfolds = []\n",
    "cm_folds = []\n",
    "logit_actual = []\n",
    "logit_prob = []\n",
    "\n",
    "# For each cross-validation batch, fit model 80:20 split, plot ROC, and get cutoff\n",
    "# TODO - add feature selection per CV\n",
    "# train, test are of type <type 'numpy.ndarray'>\n",
    "i = 0\n",
    "for (train, test) in cv.split(X, y):\n",
    "\n",
    "    test_actual = y[test]\n",
    "    test_X = X[test]\n",
    "    train_X = X[train]\n",
    "    train_y = y[train]\n",
    "    \n",
    "    # train Logit on training dataset\n",
    "    logit = LogisticRegression()\n",
    "    logit.fit(train_X, train_y)\n",
    "       \n",
    "    # test Logit on test dataset\n",
    "    # predict probability returns <type 'numpy.ndarray'> (n_samples, n_classes)\n",
    "    prob = logit.predict_proba(test_X)\n",
    "    \n",
    "    # get predicted values: 1/0; default threshold/cutoff is 0.5\n",
    "    predicted = logit.predict(test_X)\n",
    "    train_predicted = logit.predict(train_X)\n",
    "    \n",
    "    # Compute ROC curve\n",
    "    # fpr = false positive rate (1-specificity)\n",
    "    # tpr = true positive rate (sensitivity)\n",
    "    fpr, tpr, thresholds = roc_curve(test_actual, prob[:, 1]) # returns <type 'numpy.ndarray'> x 3\n",
    "    \n",
    "    # add mean Sensitivity\n",
    "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "    mean_tpr[0] = 0.0\n",
    "  \n",
    "    if output_data_to_excel:\n",
    "        output_excel('logit-fold-%d-test' % (i+1), prob, test_X, test_actual, predicted, 'TestSet%d' % (i+1))\n",
    "        output_excel('logit-fold-%d-train' % (i+1), \n",
    "                     logit.predict_proba(train_X), train_X, train_y, train_predicted, 'TrainSet%d' % (i+1))\n",
    "    # /if...\n",
    "    \n",
    "    # get_cm_row(method, foldnum, cutoff, actual, prob)\n",
    "    # append confusion matrix rows for output to Excel\n",
    "    for cutoff in test_cutoffs:\n",
    "        cm_folds.append( get_cm_row('Logit', i+1, cutoff, test_actual, prob) )\n",
    "    \n",
    "    \n",
    "    logit_actual.extend(test_actual)\n",
    "    logit_prob.extend(prob)\n",
    "    \n",
    "    roc_kfolds.append([tpr, fpr])\n",
    "    \n",
    "    #output_cutoffs(i, tpr, fpr, thresholds, prob)\n",
    "    \n",
    "    i += 1\n",
    "#/for (train, test)...\n",
    "\n",
    "show_roc(roc_kfolds, mean_tpr, mean_fpr, 'ROC Curves for Logit with K-fold Cross-validation', 2, 'logit-roc')\n",
    "\n",
    "if output_data_to_excel:\n",
    "    output_cms('logit-cms', cm_folds, 'Logit_Test_Folds') # output to excel\n",
    "  \n",
    "#Determine the best cutoff points and output confusion matrix\n",
    "#best_tp = get_confusion_matrix(0.1, logit_actual, logit_prob)\n",
    "#best_accuracy =  get_confusion_matrix(0.5, logit_actual, logit_prob)\n",
    "#show_confusion_matrix(best_tp, ['0','1'], (6,6), 12, 'logit-best-tp-cm')\n",
    "#show_confusion_matrix(best_accuracy, ['0','1'], (6,6), 12, 'logit-best-accuracy-cm')\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
